{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLwOSHIqFm9g",
        "outputId": "2c04b322-298c-4dd6-f74e-155a4481aed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndghgdqFFomK",
        "outputId": "07bea60d-7cad-43ca-fa9d-e7d0f5ae4c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Shape: (2768, 7)\n",
            "Dev Dataset Shape: (116, 7)\n",
            "Train Columns: Index(['id', 'text', 'Anger', 'Fear', 'Joy', 'Sadness', 'Surprise'], dtype='object')\n",
            "Dev Columns: Index(['id', 'text', 'Anger', 'Fear', 'Joy', 'Sadness', 'Surprise'], dtype='object')\n",
            "Missing Values in Train:\n",
            " id          0\n",
            "text        0\n",
            "Anger       0\n",
            "Fear        0\n",
            "Joy         0\n",
            "Sadness     0\n",
            "Surprise    0\n",
            "dtype: int64\n",
            "Missing Values in Dev:\n",
            " id            0\n",
            "text          0\n",
            "Anger       116\n",
            "Fear        116\n",
            "Joy         116\n",
            "Sadness     116\n",
            "Surprise    116\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "train_data = pd.read_csv(\"/content/eng.csv\")\n",
        "dev_data = pd.read_csv(\"/content/eng_a.csv\")\n",
        "\n",
        "# Inspect datasets\n",
        "print(\"Train Dataset Shape:\", train_data.shape)\n",
        "print(\"Dev Dataset Shape:\", dev_data.shape)\n",
        "print(\"Train Columns:\", train_data.columns)\n",
        "print(\"Dev Columns:\", dev_data.columns)\n",
        "print(\"Missing Values in Train:\\n\", train_data.isna().sum())\n",
        "print(\"Missing Values in Dev:\\n\", dev_data.isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yXXGOMdEGbs0"
      },
      "outputs": [],
      "source": [
        "# Fill NaN values with 0 in the development dataset\n",
        "dev_data.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bIfsecnFGezR"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove special characters and numbers\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "train_data['text'] = train_data['text'].apply(preprocess_text)\n",
        "dev_data['text'] = dev_data['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-kZ_5Q-AGhCc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Split training data into training and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    train_data['text'],\n",
        "    train_data[['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']].values,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zc6YFxpIGl2e"
      },
      "outputs": [],
      "source": [
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SZLi0Us-Gr5v"
      },
      "outputs": [],
      "source": [
        "# Tokenize text data\n",
        "def tokenize_texts(texts, tokenizer, max_length=128):\n",
        "    return tokenizer(\n",
        "        list(texts),\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "train_encodings = tokenize_texts(train_texts, tokenizer)\n",
        "val_encodings = tokenize_texts(val_texts, tokenizer)\n",
        "dev_encodings = tokenize_texts(dev_data['text'], tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9cqqpcxjGw2B"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Define the model\n",
        "class MultiLabelEmotionClassifier(nn.Module):\n",
        "    def __init__(self, model_name, num_labels):\n",
        "        super(MultiLabelEmotionClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = self.classifier(outputs.pooler_output)\n",
        "        return logits\n",
        "\n",
        "# Initialize the model\n",
        "num_labels = 5\n",
        "model = MultiLabelEmotionClassifier('bert-base-uncased', num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "d2LaCe0cG2Hc"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AdamW\n",
        "\n",
        "# Create Dataset class\n",
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zimnOpWhG_xT"
      },
      "outputs": [],
      "source": [
        "# Prepare datasets\n",
        "train_dataset = EmotionDataset(train_encodings, train_labels)\n",
        "val_dataset = EmotionDataset(val_encodings, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "VL3tTTqdHC9e"
      },
      "outputs": [],
      "source": [
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yK57XOlrHFtS",
        "outputId": "cfa35c2a-af04-41c3-bb38-194e282e17a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "loss_fn = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5_qQJ2bHHYM",
        "outputId": "7a4afa42-ee4a-4884-80f4-74129662f149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-96cd3522ea00>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.5277801769120353\n",
            "Epoch 2, Loss: 0.3639319432633264\n",
            "Epoch 3, Loss: 0.23224520512989588\n",
            "Epoch 4, Loss: 0.13458579682878086\n",
            "Epoch 5, Loss: 0.0843249094539455\n",
            "Epoch 6, Loss: 0.055035713315010074\n",
            "Epoch 7, Loss: 0.03315222029175077\n",
            "Epoch 8, Loss: 0.02661127466708422\n",
            "Epoch 9, Loss: 0.023717906445797\n",
            "Epoch 10, Loss: 0.01656039927953056\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        logits = model(input_ids, attention_mask)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {avg_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "N61Pgp8uHLKd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            preds = torch.sigmoid(logits).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "sHOWpGySHemY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, data_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)\n",
        "            preds = torch.sigmoid(logits).cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Convert predictions to binary using a threshold  (Corrected indentation)\n",
        "    threshold = 0.5\n",
        "    binary_preds = (np.array(all_preds) > threshold).astype(int)\n",
        "    f1 = f1_score(all_labels, binary_preds, average='micro')\n",
        "    return f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TssXEKJoHg_S",
        "outputId": "f765bd45-9a00-46b4-ab1e-538efb865014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-96cd3522ea00>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation F1 Score: 0.7149425287356321\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on validation set\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "f1_val = evaluate_model(model, val_loader)\n",
        "print(\"Validation F1 Score:\", f1_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on validation set\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "f1_val = evaluate_model(model, val_loader)\n",
        "print(\"Micro-Average F1 Score (micro):\", f1_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApY0BXIkb8Q_",
        "outputId": "1deb9c04-2674-47cb-c58f-83b323b41716"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-96cd3522ea00>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Micro-Average F1 Score (micro): 0.7149425287356321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "HgTXMwzDI7SP"
      },
      "outputs": [],
      "source": [
        "def predict_emotions(sentence):\n",
        "    # Tokenize the input\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", max_length=128, truncation=True, padding=\"max_length\").to(device)\n",
        "\n",
        "    # Get the model's predictions\n",
        "    with torch.no_grad():\n",
        "        # Only pass input_ids and attention_mask to the model\n",
        "        logits = model(inputs['input_ids'], inputs['attention_mask'])\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "    # Define emotion labels\n",
        "    emotion_labels = ['Anger', 'Fear', 'Joy', 'Sadness', 'Surprise']\n",
        "\n",
        "    # Get predicted emotions based on a threshold (e.g., 0.5)\n",
        "    predicted_emotions = [emotion_labels[i] for i, prob in enumerate(probs[0]) if prob > 0.5]\n",
        "\n",
        "    return predicted_emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5sl0I_jJjCY",
        "outputId": "c13ddd08-5884-43f3-b4ae-e338650a3671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotions: ['Joy']\n"
          ]
        }
      ],
      "source": [
        "sentence = \"She threw a party for her Graduation\"\n",
        "result = predict_emotions(sentence)\n",
        "print(\"Predicted Emotions:\", result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nR0mbKMVSIlS"
      },
      "execution_count": 37,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}